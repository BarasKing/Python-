### 信息标记的三种形式
>XML JSON YAML

#### XML
- XML，扩展标记语言，采用了以标签为主来构建信息，表达信息的方式

如,在标签Tag中有内容时，有名称Name：img，有属性Attributes：src='china.jpg',size='10'

    <img src='china,jpg' size='10'>...</img>
在标签中没有内容时，可以用缩写形式，直接用一对尖括号来表示一个标签

    <img src='china,jpg' size='10'>
也可以嵌入注释

    <!-- This is a comment,very useful -->

#### JSON
- JSON，有类型的键值对key:value构成的信息表达方式

JSON有三种形式：
    "key":"value"
    "key":["value1","value2"] #对应于python的列表
    "key":{"subkey1":"subvalue1" #对应于python的字典
           "subkey2":"subvalue2"}

#### YMAL
- YMAL，无类型的键值对 key:name

通过缩进来表达所属关系，如：

    name:
        newname:北京理工大学
        oldname:延安自然科学院

用减号-表达并列关系，如：

    name:
    -北京理工大学
    -延安自然科学院
用|表达整块数据，#表示注释，如：
    
    text: | #下面是一段介绍
    ********************
    ********************
    ********************
#### 信息提取的一般方法
- 方法一：完整解析信息的标记形式，再提取关键信息，如bs4库的标签树遍历
- 方法二：无视标记形式，直接搜索关键信息，对信息的文本直接查找即可
- 融合方法：结合形式解析与搜索方法，提取关键信息，如提取HTML中所有URL标签<br>
1、搜索到所有<a>标签，文本搜索<br> 
2、解析<a>标签格式，提取href后的链接内容，内容解析<br>

代码如下：
    
    >>> for link in soup.find_all('a'):
            print(link.get('href'))
    http://www.icourse163.org/course/BIT-268001
    http://www.icourse163.org/course/BIT-1001870001
#### 基于bs4库的HTML内容查找方法
>由于bs4库的find_all()方法特别常用，因此有简写形式，即：<tag>(...)等价于<tag>.find_all(...) 和 soup(...)等价于soup.find_all(...)
- <>.find_all(name,attrs,recursive,string,\*\*kwargs) 返回一个**列表**类型，存储查找的结果

**name**：对标签名称的检索字符串,若要查找多个标签，将之以列表形式作为参数传入，如['a','b','p']；若输入的标签名为True，则返回所有标签信息；若要查找以b开头的所有标签，包括<b>,<body>等，则需要用正则表达式
    
    #单个标签信息查找
    >>> soup.find_all('a')
    [<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]
    
    #多个标签信息查找
    >>> soup.find_all(['a','b'])
    [<b>The demo python introduces several python courses.</b>, <a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]
   
    #输入标签名为True，返回所有标签信息
    >>> for tag in soup.find_all(True):
    ...     print(tag.name)
    ...
    html
    head
    title
    body
    p
    b
    p
    a
    a    

    #查找以b开头的所有标签信息
    >>> import re
    >>> for tag in soup.find_all(re.compile('b'))：
            print(tag.name)
    body
    b
    
**attrs**：对标签属性值的检索字符串，可标注属性检索

    #查找包含'course'属性值的<p>标签，相当于给检索的<p>加个条件限制，必须带有某个属性值
    >>> soup.find_all('p','course')
    [<p class="course">Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:
    <a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a> and <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>.</p>]
    
    #查找包含 id='link1' 的标签元素
    >>> soup.find_all(id='link1')
    [<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>]
    
    #查找包含 id='link' 的标签元素，发现并没有包含id='link'的标签，但是存在id='link1'的标签，也就是说在对属性查找时，必须精确赋值这个信息
    >>> soup.find_all(id='link')
    []
    
    #如果要对属性的部分信息进行查找，如查找以link开头的所有标签信息(link1,link2...)，则需要正则表达式的支持
    >>> import re
    >>> soup.find_all(id=re.compile('link'))
    [<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]
    #正则表达式类似于搜索关键词一样，是搜索词的一部分
    
**recursive**：是否对子孙全部检索，默认为True，如果只想搜索当前节点的儿子节点
    
    #先查找所有soup的子孙节点中的a标签
    >>> soup.find_all('a')
    [<a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a>, <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>]
    #再查找soup儿子节点中的a标签，显示为无，说明a标签都不是soup的直接儿子节点，为子孙后续节点
    >>> soup.find_all('a',recursive=False)
    []
    
**string**：<>...</>中字符串区域的检索字符串，检索到的结果是一对<>之间的Navigablestring内容组成的列表

    >>> soup #查看soup的内容
    <html><head><title>This is a python demo page</title></head>
    <body>
    <p class="title"><b>The demo python introduces several python courses.</b></p>
    <p class="course">Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:
    <a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1">Basic Python</a> and <a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2">Advanced Python</a>.</p>
    </body></html>
    >>> soup.find_all(string='Basic Python') #查找一对<>之间的Navigablestring为'Basic Python'的内容
    ['Basic Python']
    >>> import re
    >>> soup.find_all(string=re.compile('python')) #使用正则表达式，查找一对<>之间的内容中含有'python'这一信息的Navigablestring内容
    ['This is a python demo page', 'The demo python introduces several python courses.']

<tag>(...) <=> <tag>.find_all(...)  soup(...) <=> soup.find_all(...)
    
    >>> soup(string=re.compile('demo')) #简写形式
    ['This is a python demo page', 'The demo python introduces several python courses.']
    >>> soup.find_all(string=re.compile('demo')) #原形式
    ['This is a python demo page', 'The demo python introduces several python courses.']

- <>.find_all()方法的扩展方法，其参数与find_all()参数一致<br>
<>.find()：搜索且只返回一个结果，字符串类型<br>
<>.find_parents：在先辈节点中搜索，返回列表类型<br>
<>.find_parent：在先辈节点中返回一个结果，字符串类型<br>
<>.find_next_siblings()：在后续平行节点中搜索，返回列表类型<br>
<>.find_next_sibling()：在后续平行节点中返回一个结果，字符串类型<br>
<>.find_previous_siblings()：在前序平行节点中搜索，返回列表类型<br>
<>.find_previous_sibling()：在前序平行节点中返回一个结果，字符串类型<br>

#### 实例：大学排名爬虫
>输入为：大学排名URL链接，输出为：大学排名信息的屏幕输出（排名，大学名称，总分），技术路线：requests-bs4（只能满足静态网站的爬取），定向爬虫：仅对输入URL进行爬取，不扩展爬取
##### 程序的结构设计
- 步骤1：从网络上获取大学排名网页内容 ,getHTMLtext()
- 步骤2：提取网页内容中信息到合适的数据结构（关键）,fillUnivList()
- 步骤3：利用数据结构展示并输出结果 ,printUnivList()

操作实例如下：

    # UnivList.py
    import requests
    from bs4 import BeautifulSoup
    import bs4

    def getHTMLText(url):
        try:
            r = requests.get(url, timeout=30)
            r.raise_for_status()
            r.encoding = r.apparent_encoding
            return r.text
        except:
            return ''
            
    def fillUnivList(ulist, html):
        soup = BeautifulSoup(html, 'html.parser')
        for tr in soup.find('tbody').children:
            if isinstance(tr, bs4.element.Tag):  # 检测tr标签的类型，如果不是bs4库定义的Tag类型，将被过滤掉
                tds = tr('td')  # 即find_all方法的简写，将td标签的字符串存到tds中
                # 将每一个Tag类型的tr里的td标签内容先提取为一个包含大学排名、大学名称、大学排分的列表，将这个列表作为一个元素存到ulist列表中
                ulist.append([tds[0].string, tds[1].string, tds[2].string])

    # def printUnivList(ulist, num): #由于使用英文字符填充对齐，会出现不整齐的情况，此时应使用中文空格chr(12288)来填充
    #     print('{:^10}\t{:^6}\t{:^10}'.format('排名', '学校名称', '总分'))
    #     for i in range(num):
    #         u = ulist[i]
    #         print('{:^10}\t{:^6}\t{:^10}'.format(u[0], u[1], u[2]))

    def printUnivList(ulist, num): #使用中文空格chr(12288)来填充
        tplt = '{0:^10}\t{1:{3}^10}\t{2:^10}'
        print(tplt.format('排名', '学校名称', '总分', chr(12288)))
        for i in range(num):
            u = ulist[i]
            print(tplt.format(u[0], u[1], u[2], chr(12288)))

    def main():
        uinfo = []
        url = 'http://www.zuihaodaxue.cn/zuihaodaxuepaiming2019.html'
        html = getHTMLText(url)
        fillUnivList(uinfo, html)
        printUnivList(uinfo, 20)

    main()

